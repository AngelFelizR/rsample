
`rsample` can be used to create objects containing resamples of the original data. This page contains examples of how those objects can be used for data analysis. 

For illustration, the `Sacramento` housing data is used to demonstrate. From the `caret` package:

> This data frame contains house and sale price data for 932 homes in Sacramento CA. The original data were obtained from the website for the SpatialKey software. From their website: "The Sacramento real estate transactions file is a list of 985 real estate transactions in the Sacramento area reported over a five-day period, as reported by the Sacramento Bee." Google was used to fill in missing/incorrect data.

The data can be accessed using 

```{r Sacramento, message=FALSE}
library(caret)
data(Sacramento)
str(Sacramento)
```
```{r setup, include=FALSE}
theme_set(theme_bw())
```
## Model Assessment

Let's fit a linear regression model to the data with model terms for the number of bedrooms, the number of bathrooms, the square footage, and the type of house ('Condo', 'Multi_Family', or 'Residential'). 

If we were fitting the model to the entire data set, we might model the logarithm of the sale price using
```r
lm(log(price) ~ beds + baths + sqft + type, data = Sacramento)
```
To evaluate this model, we will use 10 repeats of 10-fold cross-validation and use the 100 holdout samples to evaluate the root mean squared error (in log dollar units). 

First, let's make the splits of the data:
```{r model_vfold, message=FALSE}
library(rsample)
set.seed(4622)
rs_obj <- vfold_cv(Sacramento, V = 10, repeats = 10)
head(dim(rs_obj))
```
Now let's write a function that will, for each resample:

1. obtain the analysis data set (i.e. the 90% used for modeling)
1. fit a linear model
1. predict the assessment data (the other 10% not used for the model) using the `broom` package
1. calculate the residuals on the assessment data

Here is our function:

```{r lm_func}
library(broom)
## splits will be the `rsplit` object with the 90/10 partition
holdout_resids <- function(splits, ...) {
  # Fit the model to the 90%
  mod <- lm(..., data = as.data.frame(splits, "analysis"))
  # Save the 10%
  holdout <- as.data.frame(splits, "assessment")
  # `augment` will save the predictions with the holdout data set
  res <- broom::augment(mod, newdata = holdout)
  # Calculate the residuals
  res$.resid <- log(holdout$price) - res$.fitted
  # Return the assessment data set wit the additional columns
  res
}
```

For example: 

```{r onefold}
str(
  holdout_resids(rs_obj$splits$splits[[1]], 
                 log(price) ~ beds + baths + sqft + type
  )
)
```

To compute this data set for each of the 100 resamples: 

```{r model_along, message=FALSE}
rs_obj$splits$results <- along(rs_obj, 
                               holdout_resids, 
                               log(price) ~ beds + baths + sqft + type)
rs_obj$splits
```

Now we can compute the RMSE values for all of the assessment data sets: 

```{r model_rmse}
rmse <- function(x) sqrt(mean(x$.resid^2))
rs_obj$splits$rmse <- along(rs_obj, rmse, .elem = "results", .unlist = TRUE)
summary(splits(rs_obj, .elem = "rmse"))
```

## Using the Bootstrap to Make Comparisons

Traditionally, the bootstrap has been primarily used to empirically determine the sampling distribution of a test statistic. Given a set of samples with replacement, a statistic can be calculated on each analysis set and the results can be used to make inferences (such as confidence intervals).

Consider the types of properties in these data. Are there differences in the sale prices between groups? 

```{r type_plot}
ggplot(Sacramento, aes(x = type, y = price)) + 
  geom_boxplot() + 
  scale_y_log10()
```

If we wanted to compare the residential and multi-family properties, we could conduct a _t_-test on the logarithm of the sale prices. Instead, let's use the bootstrap to see if there is a difference in the average sale prices for the two groups in the regular dollar units. We need a simple function to compute this statistic on the resample:

```{r mean_diff}
mean_diff <- function(splits) {
  x <- as.data.frame(splits)
  mean(x$price[x$type == "Residential"]) - 
      mean(x$price[x$type == "Multi_Family"])     
}
```

Now we can create a large number of bootstrap samples. We won't need the assessment set, so the option `oob = FALSE` is used to skip computing and storing these data sets. 

```{r boot_mean_diff}
set.seed(353)
bt_resamples <- bootstraps(Sacramento, times = 2000, oob = FALSE)
```

This function is then computed across each resample:

```{r stats}
bt_resamples$splits$statistic <- along(bt_resamples, 
                                       mean_diff, 
                                       .unlist = TRUE)
```

The bootstrap distribution of this statistic looks fairly well-behaved: 

```{r stats_plot}
ggplot(bt_resamples$splits, aes(x = statistic)) + 
  geom_line(stat = "density", adjust = 1.25) + 
  xlab("Mean(Residential) - Mean(Multi_Family)")
```

The variation is considerable in this statistic. One method of computing a confidence interval is to take the percentiles of the bootstrap distribution. A 95% confidence interval for the difference in the means would be:

```{r ci}
quantile(splits(bt_resamples, .elem = "statistic"), 
         probs = c(0.025, 0.500, 0.975))
```
_On average_, there is no evidence for a difference in the sale prices in these types of homes. 

## Bootstrap Estimates of Model Coefficients

```{r coefs}
lm_coefs <- function(splits, ...) {
  mod <- lm(..., data = as.data.frame(splits))
  as.data.frame(t(coef(mod)))
}
coef_values <- along(bt_resamples, lm_coefs, log(price) ~ beds + baths + sqft + type)
coef_values <- do.call("rbind", coef_values)
```

## Using recipes

The [`recipes`](https://topepo.github.io/recipes/) package contains a data preprocessor that can be used to avoid the potentially expensive formula methods as well as providing a richer set of data manipulation tools than base R can provide. 

To use a recipe to define the resampled design matrix, an initial recipe is created: 
```{r initial_rec, message=FALSE}
library(recipes)

rec <- recipe(price ~ beds + baths + sqft + type, data = Sacramento) %>%
  step_dummy(type) %>%
  step_log(price) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())
rec
```
This recreates the work that the formula method uses with the additional steps that center and scale the predictors. While the original data object `Sacramento` is used in the call, it is only used to define the variables and their characteristics. The recipe can be estimated on the analysis component of the resample. 

A function to fit the linear models using a recipe would then be:

```{r recipe_fit}
lm_coefs_rec <- function(splits, rec, ...) {
  # Get the analysis data set from the resample
  training_data <- as.data.frame(splits)
  # Estimate the parameters using these data
  trained_rec <- learn(rec, training = training_data, verbose = FALSE)
  # Apply the transformations to the data set and convert to a matrix
  design_matrix <- process(trained_rec, newdata = training_data, all_predictors())
  design_matrix <- as.matrix(design_matrix)
  # Get the logged price values and fit the model using `lm.fit`
  y <- process(trained_rec, newdata = training_data, all_outcomes())$price
  lm.fit(x = design_matrix, y = y, ...)
}

bt_resamples$splits$fits <- along(bt_resamples, lm_coefs_rec, rec = rec)
bt_resamples$splits
```
From these objects, we can extract the coefficients, fit statistics, and other values.

## Keeping Tidy

The [`broom` package](https://cran.r-project.org/package=broom) contains a class called `tidy` that created representations of objects that can be easily used for analysis, plotting, etc. `rsample` contains `tidy` methods for `rset` and `rsplit` objects. For example: 

```{r tidy_rsplit}
first_resample <- splits(bt_resamples, .elem = "splits")[[1]]
class(first_resample)
tidy(first_resample)
```

and

```{r tidy_rset}
class(bt_resamples)
tidy(bt_resamples)
```


